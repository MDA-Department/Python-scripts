{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5568a0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgoktas\\OneDrive - aft.org\\testing_locals\\00111_15099\\00111_15099_20201120_KnackBuild.xlsx\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'er' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ab98a7a37209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ab98a7a37209>\u001b[0m in \u001b[0;36mmatcher\u001b[1;34m(member_file_path, entity_file_path, member_entity_category_tuple)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmember_id_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_file_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmember_entity_category_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-ab98a7a37209>\u001b[0m in \u001b[0;36mentity_file_creator\u001b[1;34m(entity_file_path, ws_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mentity_file_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mentity_sheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcol_name_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[A-Z][^A-Z]*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1072\u001b[0m                     \u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(path, content, storage_options)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m    950\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\pgoktas\\\\OneDrive - aft.org\\\\testing_locals\\\\00111_15099\\\\00111_15099_Entity.xlsx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ab98a7a37209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0mer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'er' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import recordlinkage\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def entity_file_creator(entity_file_path, ws_name):\n",
    "    entity_sheet = pd.read_excel(entity_file_path, ws_name)\n",
    "    col_name_list = re.findall('[A-Z][^A-Z]*', ws_name)\n",
    "    col_name = ' '.join(col_name_list) + ' Name'\n",
    "    if (len(entity_sheet[col_name].dropna()) > 0) == True:\n",
    "        col_id = ' '.join(col_name_list) + ' Id'\n",
    "        entity_descriptions = entity_sheet[col_name].str.rstrip()\n",
    "        entity_ids = entity_sheet[col_id]\n",
    "        return pd.DataFrame({col_name: entity_descriptions,col_id: entity_ids}).dropna()    \n",
    "    \n",
    "def member_id_creator(member_file_path, col_name):\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    if (len(member_file[col_name].dropna()) > 0) == True:\n",
    "        member_descriptions = member_file[col_name].unique().tolist()\n",
    "        return pd.DataFrame({col_name : member_descriptions}) \n",
    "    \n",
    "def clean(df,col_name):\n",
    "    df[col_name+'_clean'] = df[col_name]\n",
    "    df[col_name+'_clean'].replace('\\d+', '', regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\(', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\)', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Elem Sch', 'Elementary',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High School', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Middle Sch', 'MS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High Sch', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'] = df[col_name+'_clean'].str.rstrip(' ')\n",
    "    return df\n",
    "\n",
    "def matcher(member_file_path, entity_file_path, member_entity_category_tuple):        \n",
    "    mem_name = member_entity_category_tuple[0]\n",
    "    enti_name_list = re.findall('[A-Z][^A-Z]*', member_entity_category_tuple[1])\n",
    "    enti_name = ' '.join(enti_name_list) + ' Name'\n",
    "    enti_id = ' '.join(enti_name_list) + ' Id'\n",
    "    member = member_id_creator(member_file_path, mem_name)\n",
    "    entity = entity_file_creator(entity_file_path, member_entity_category_tuple[1])\n",
    "    \n",
    "    if entity is not None and member is not None:\n",
    "        member = clean(member, mem_name)\n",
    "    \n",
    "        cleaned_mem_name = mem_name+'_clean'\n",
    "        \n",
    "        #perfect matching\n",
    "        perf_matches = member.merge(entity, how='inner', left_on=cleaned_mem_name, right_on=enti_name)\n",
    "        member_wo_perf_matches = member[~member[mem_name].isin(perf_matches[mem_name])]\n",
    "        entity_wo_perf_matches = entity[~entity[enti_id].isin(perf_matches[enti_id])]\n",
    "\n",
    "        #fuzzy matching\n",
    "        member_wo_perf_matches.set_index(mem_name,inplace=True)\n",
    "        entity_wo_perf_matches.set_index(enti_id,inplace=True)\n",
    "        indexer = recordlinkage.Index()\n",
    "        indexer.full()\n",
    "        candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "        compare = recordlinkage.Compare()\n",
    "        compare.string(cleaned_mem_name,enti_name,threshold=0.6,label='similarity')\n",
    "        features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "        potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "\n",
    "        entity_lu = entity_wo_perf_matches[[enti_name]].reset_index()\n",
    "        member_lu = member_wo_perf_matches[[cleaned_mem_name]].reset_index()\n",
    "        entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "        fuzzy_matches = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "    \n",
    "        if len(perf_matches) !=  0: perf_matches['type'] = ['Perfect Match']*len(perf_matches) \n",
    "        if len(fuzzy_matches) !=  0:\n",
    "            fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == False, 'type'] = 'One-to-One Fuzzy Match'\n",
    "            fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == True, 'type'] = 'Multiple Fuzzy Matches'\n",
    "            fuzzy_matches.loc[fuzzy_matches[enti_id].isna(), 'type'] = 'No Match to Entity File Found'\n",
    "    \n",
    "        concat = pd.concat([fuzzy_matches,perf_matches])\n",
    "        #print(str(member_file_path)[:-24])\n",
    "        concat.to_csv(str(member_file_path)[:-24] + \"{}_match.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        print('Both membership and entity file data exist for {}. Fuzzy match spreadsheet created.'.format(member_entity_category_tuple))\n",
    "    elif entity is None and member is not None:\n",
    "        member.to_csv(str(member_file_path)[:-24] + \"{}_member.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        print('The membership file data exists for {} but entity file data does not.'.format(member_entity_category_tuple))\n",
    "        print('A spreadsheet of entries in the membership file has been created.')\n",
    "        print('The affiliate may need to be contacted to create entity file categories.')\n",
    "    elif entity is not None and member is None:\n",
    "        print('The entity file data exists for {} but membership file data does not.'.format(member_entity_category_tuple))\n",
    "        print('No spreadsheet created.')\n",
    "    else:\n",
    "        print('Neither membership nor entity file data exists.')\n",
    "        print('No spreadsheet created.')\n",
    "\n",
    "categories = [('JobDescription','JobTitle'),('LocalJobClassName','LocalJobClass'),('WorkLocationName','WorkLocation'),('WorkStructureName','WorkStructure')]\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\OneDrive - aft.org\\testing_locals\"\n",
    "        \n",
    "pathlist = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist:\n",
    "    member_file_path = path\n",
    "    print(path)\n",
    "    #put limit here so only knackbuild files with correct str length get processed? prevent possible errors/bugs?\n",
    "    entity_file_path = str(path)[:-24] + 'Entity.xlsx'\n",
    "    entity_file_path = Path(entity_file_path)\n",
    "    for category in categories:\n",
    "        try:\n",
    "            match = matcher(member_file_path, entity_file_path, category)\n",
    "        except:\n",
    "            print('Error')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3f6660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\00111_15099\\00111_15099_JobDescription_match.csv\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\00111_15099\\00111_15099_WorkLocationName_match.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\"\n",
    "\n",
    "#creating new copy of membership file to work in so original file is preserved\n",
    "pathlist_knackbuild = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist_knackbuild:\n",
    "    shutil.copy(path, str(path)[:-5] + '_w_entityids.xlsx')\n",
    "\n",
    "pathlist_fuzzymatch = Path(directory).glob('**/*_match.csv')\n",
    "for path in pathlist_fuzzymatch:\n",
    "    print(path)\n",
    "    fuzzy_match_file = pd.read_csv(path)\n",
    "    member_file_path = list(Path(str(path)[0:82]).glob('**/*Knackbuild_w_entityids.xlsx'))[0]\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    \n",
    "    match_col_name = str(path).split(\"_\")[7]\n",
    "    merged_file = member_file.merge(fuzzy_match_file, on = match_col_name, how='left')\n",
    "    \n",
    "    match_col_name_list = re.findall('[A-Z][^A-Z]*', match_col_name) #creating vars for id with spaces and id without spaces\n",
    "    \n",
    "    if 'Name' in match_col_name_list:          #remove once jobdescription switched out to jobtitle in categories\n",
    "        match_col_spaces = ' '.join(match_col_name_list) #creating var for name without spaces\n",
    "        match_col_name_list.remove('Name')\n",
    "        match_col_id_spaces = ' '.join(match_col_name_list) + ' Id'\n",
    "        match_col_id_no_spaces = ''.join(match_col_name_list) + 'Id'\n",
    "    else:  #remove once jobdescription switched out to jobtitle in categories\n",
    "        match_col_id_spaces = 'Job Title Id'  #remove once jobdescription switched out to jobtitle in categories\n",
    "        match_col_id_wo_spaces = 'JobTitleId'  #remove once jobdescription switched out to jobtitle in categories\n",
    "        match_col_spaces = 'Job Title Name' #creating var for name without spaces\n",
    "    \n",
    "    merged_file[match_col_name] = merged_file[match_col_spaces]\n",
    "    merged_file[match_col_id_no_spaces] = merged_file[match_col_id_spaces] \n",
    "    merged_file.drop([match_col_spaces, match_col_id_spaces, match_col_name + \"_clean\", \"type\"],axis=1,inplace=True)  #drop match_col_spaces + match_col_id_spaces\n",
    "    \n",
    "    merged_file.to_excel(member_file_path,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7ea223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\AFTDBFileUpload\\00003_12857\\00003_12857_20200903_Knackbuild.xlsx\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\AFTDBFileUpload\\00003_13259\\00003_13259_20200916_KnackBuild.xlsx\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\AFTDBFileUpload\\00003_13698\\00003_13698_20200930_KnackBuild.xlsx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bf0d89b18ca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpathlist_knackbuild\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'JobDescription'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EXISTS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         data = io.parse(\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mDataFrame\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mExcel\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m         \"\"\"\n\u001b[1;32m-> 1170\u001b[1;33m         return self._reader.parse(\n\u001b[0m\u001b[0;32m   1171\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sheet_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_usecols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_data\u001b[1;34m(self, sheet, convert_float)\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mScalar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mlast_row_with_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 548\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mrow_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    549\u001b[0m             \u001b[0mconverted_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_float\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconverted_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py\u001b[0m in \u001b[0;36m_cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m                                  \u001b[0mdata_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                                  date_formats=self.parent._date_formats)\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_row\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_row\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add a finaliser to close the source when this becomes possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m             \u001b[0mtag_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtag_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36miterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1227\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpullparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m                 \u001b[1;31m# load event buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[0;32m   1018\u001b[0m                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "pathlist_knackbuild = Path(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\AFTDBFileUpload\").glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist_knackbuild:\n",
    "    print(path)\n",
    "    file = pd.read_excel(path)\n",
    "    if ((len(file['JobDescription'].dropna()) > 0) == True):\n",
    "        print('EXISTS')\n",
    "    elif ((len(file['LocalJobClassName'].dropna()) > 0) == True):\n",
    "        print('EXISTS')\n",
    "    elif ((len(file['WorkLocationName'].dropna()) > 0) == True):\n",
    "        print('EXISTS')\n",
    "    elif ((len(file['WorkStructureName'].dropna()) > 0) == True):\n",
    "        print('EXISTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5ad26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "import pandas as pd\n",
    "import recordlinkage\n",
    "\n",
    "#perfect matches\n",
    "member = pd.read_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\member_unique_jds_clean.csv\")\n",
    "entity = pd.read_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\entity_unique_jds.csv\")\n",
    "\n",
    "perf_matches = member.merge(entity, how='inner', left_on='jd_m', right_on='jd_e')\n",
    "#print(perf_matches)\n",
    "#perf_matches.to_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\perf_matches.csv\",index=False)\n",
    "member_wo_perf_matches = member[~member['id_m'].isin(perf_matches['id_m'])]\n",
    "entity_wo_perf_matches = entity[~entity['id_e'].isin(perf_matches['id_e'])]\n",
    "\n",
    "#fuzzy matching\n",
    "member_wo_perf_matches.set_index('id_m',inplace=True)\n",
    "entity_wo_perf_matches.set_index('id_e',inplace=True)\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "compare = recordlinkage.Compare()\n",
    "compare.string('jd_m','jd_e',threshold=0.6,label='similarity', missing_value = 'close_match_not_found')\n",
    "features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "#print(potential_matches)\n",
    "\n",
    "entity_lu = entity_wo_perf_matches[['jd_e']].reset_index()\n",
    "member_lu = member_wo_perf_matches[['jd_m']].reset_index()\n",
    "#print(entity_lu)\n",
    "#print(member_lu)\n",
    "entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "final_merge = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "#final_merge.to_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\fuzzy_match_test.csv\",index=False)\n",
    "\n",
    "#quality control\n",
    "concat_test = pd.concat([final_merge,perf_matches])\n",
    "#concat_test.to_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\concat_test.csv\",index=False)\n",
    "completeness_test = final_merge.merge(member, on='id_m',how='outer') #.drop([jd_m_x],axis=1)\n",
    "completeness_test.to_csv(r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\completeness_test.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f4bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\06732_17784\\06732_17784_20210318_Knackbuild.xlsx\n",
      "No data exists in JobDescription\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b21d33b97eda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"{}_match.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fuzzy match spreadsheet created.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b21d33b97eda>\u001b[0m in \u001b[0;36mmatcher\u001b[1;34m(member_file_path, entity_file_path, member_entity_category_tuple)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0menti_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menti_name_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmember_id_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_file_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmember_entity_category_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mmember\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b21d33b97eda>\u001b[0m in \u001b[0;36mentity_file_creator\u001b[1;34m(entity_file_path, ws_name)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcol_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Name'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcol_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_name_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' Id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mentity_descriptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_sheet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mentity_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity_sheet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity_sheet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5459\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5460\u001b[0m         ):\n\u001b[1;32m-> 5461\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5462\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import recordlinkage\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def entity_file_creator(entity_file_path, ws_name):\n",
    "    entity_sheet = pd.read_excel(entity_file_path, ws_name)\n",
    "    col_name_list = re.findall('[A-Z][^A-Z]*', ws_name)\n",
    "    col_name = ' '.join(col_name_list) + ' Name'\n",
    "    col_id = ' '.join(col_name_list) + ' Id'\n",
    "    entity_descriptions = entity_sheet[col_name].str.rstrip()\n",
    "    entity_ids = entity_sheet[col_id]\n",
    "    if (len(entity_sheet[col_name].dropna()) > 0) == False:\n",
    "        print('Spreadsheet created but entity file missing all data. Entity file classes must be created.')\n",
    "    return pd.DataFrame({col_name: entity_descriptions,col_id: entity_ids}).dropna() \n",
    "    \n",
    "def member_id_creator(member_file_path, col_name):\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    if (len(member_file[col_name].dropna()) > 0) == True:\n",
    "        member_descriptions = member_file[col_name].unique().tolist()\n",
    "        member_ids = [uuid.uuid4() for x in range(len(member_descriptions))]\n",
    "        print('Data exists in ' + col_name)\n",
    "        return pd.DataFrame({col_name : member_descriptions, '{}ID'.format(col_name) : member_ids}) \n",
    "    else:\n",
    "        print('No data exists in ' + col_name \" in the membership file.\") \n",
    "    \n",
    "def clean(df,col_name):\n",
    "    df[col_name+'_clean'] = df[col_name]\n",
    "    df[col_name+'_clean'].replace('\\d+', '', regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\(', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\)', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Elem Sch', 'Elementary',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High School', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Middle Sch', 'MS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High Sch', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'] = df[col_name+'_clean'].str.rstrip(' ')\n",
    "    return df\n",
    "\n",
    "def matcher(member_file_path, entity_file_path, member_entity_category_tuple):        \n",
    "    mem_name = member_entity_category_tuple[0]\n",
    "    mem_id = '{}ID'.format(mem_name)\n",
    "    enti_name_list = re.findall('[A-Z][^A-Z]*', member_entity_category_tuple[1])\n",
    "    enti_name = ' '.join(enti_name_list) + ' Name'\n",
    "    enti_id = ' '.join(enti_name_list) + ' Id'\n",
    "    member = member_id_creator(member_file_path, mem_name)\n",
    "    entity = entity_file_creator(entity_file_path, member_entity_category_tuple[1])\n",
    "    \n",
    "    member = clean(member, mem_name)\n",
    "    \n",
    "    cleaned_mem_name = mem_name+'_clean'\n",
    "    \n",
    "    perf_matches = member.merge(entity, how='inner', left_on=cleaned_mem_name, right_on=enti_name)\n",
    "    member_wo_perf_matches = member[~member[mem_id].isin(perf_matches[mem_id])]\n",
    "    entity_wo_perf_matches = entity[~entity[enti_id].isin(perf_matches[enti_id])]\n",
    "\n",
    "    #fuzzy matching\n",
    "    member_wo_perf_matches.set_index(mem_id,inplace=True)\n",
    "    entity_wo_perf_matches.set_index(enti_id,inplace=True)\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.full()\n",
    "    candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "    compare = recordlinkage.Compare()\n",
    "    compare.string(cleaned_mem_name,enti_name,threshold=0.6,label='similarity')\n",
    "    features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "    potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "\n",
    "    entity_lu = entity_wo_perf_matches[[enti_name]].reset_index()\n",
    "    member_lu = member_wo_perf_matches[[cleaned_mem_name,mem_name]].reset_index()\n",
    "    entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "    fuzzy_matches = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "    \n",
    "    perf_matches['type'] = ['Perfect Match']*len(perf_matches)\n",
    "    fuzzy_matches.loc[fuzzy_matches[mem_id].duplicated(keep=False) == False, 'type'] = 'One-to-One Fuzzy Match'\n",
    "    fuzzy_matches.loc[fuzzy_matches[mem_id].duplicated(keep=False) == True, 'type'] = 'Multiple Fuzzy Matches'\n",
    "    fuzzy_matches.loc[fuzzy_matches[enti_id].isna(), 'type'] = 'No Match to Entity File Found'\n",
    "    \n",
    "    concat = pd.concat([fuzzy_matches,perf_matches])\n",
    "    return concat\n",
    "\n",
    "categories = [('JobDescription','JobTitle'),('LocalJobClassName','LocalJobClass'),('WorkLocationName','WorkLocation'),('WorkStructureName','WorkStructure')]\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\"\n",
    "        \n",
    "pathlist = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist:\n",
    "    member_file_path = path\n",
    "    print(path)\n",
    "    #put limit here so only knackbuild files with correct str length get processed? prevent possible errors/bugs?\n",
    "    entity_file_path = str(path)[:-24] + 'Entity.xlsx'\n",
    "    entity_file_path = Path(entity_file_path)\n",
    "    for category in categories:\n",
    "        try:\n",
    "            match = matcher(member_file_path, entity_file_path, category)\n",
    "            match.to_csv(str(path)[:-24] + \"{}_match.csv\".format(category[0]),index=False)\n",
    "            print('Fuzzy match spreadsheet created.')\n",
    "        except TypeError:\n",
    "            print('No data exists in {} in the membership file. Spreadsheet not created.'.format(category[0]))\n",
    "        except FileNotFoundError:\n",
    "            print('Entity file does not exist. Spreadsheet not created.')\n",
    "        #except KeyError:\n",
    "        #    print('No data exists in {} in the entity file. A spreadsheet of matches between the entity and membership file will not be created.'.format(category[1]))\n",
    "        #except:\n",
    "        #    print('TESTING TESTING TESTING')\n",
    "        #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddea9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227a8625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\00111_15099\\00111_15099_20201120_KnackBuild.xlsx\n",
      "Data exists in JobDescription for the membership file.\n",
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
      "Fuzzy match spreadsheet created.\n",
      "No data exists in LocalJobClassName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "Data exists in WorkLocationName for the membership file.\n",
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
      "Fuzzy match spreadsheet created.\n",
      "Data exists in WorkStructureName for the membership file.\n",
      "No data exists in Work Structure Name the entity file.\n",
      "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed Spreadsheet not created.\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\06732_17784\\06732_17784_20210318_Knackbuild.xlsx\n",
      "No data exists in JobDescription for the membership file.\n",
      "No data exists in Job Title Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in LocalJobClassName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkLocationName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkStructureName for the membership file.\n",
      "No data exists in Work Structure Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\06732_18970\\06732_18970_20210507_Knackbuild.xlsx\n",
      "No data exists in JobDescription for the membership file.\n",
      "No data exists in Job Title Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in LocalJobClassName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkLocationName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkStructureName for the membership file.\n",
      "No data exists in Work Structure Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\\06814_19383\\06814_19383_20210525_Knackbuild.xlsx\n",
      "No data exists in JobDescription for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in LocalJobClassName for the membership file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkLocationName for the membership file.\n",
      "No data exists in Work Location Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n",
      "No data exists in WorkStructureName for the membership file.\n",
      "No data exists in Work Structure Name the entity file.\n",
      "'NoneType' object is not subscriptable Spreadsheet not created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import recordlinkage\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def entity_file_creator(entity_file_path, ws_name):\n",
    "    entity_sheet = pd.read_excel(entity_file_path, ws_name)\n",
    "    col_name_list = re.findall('[A-Z][^A-Z]*', ws_name)\n",
    "    col_name = ' '.join(col_name_list) + ' Name'\n",
    "    if (len(entity_sheet[col_name].dropna()) > 0) == True:\n",
    "        col_id = ' '.join(col_name_list) + ' Id'\n",
    "        entity_descriptions = entity_sheet[col_name].str.rstrip()\n",
    "        entity_ids = entity_sheet[col_id]\n",
    "        return pd.DataFrame({col_name: entity_descriptions,col_id: entity_ids}).dropna()    \n",
    "    elif (len(entity_sheet[col_name].dropna()) > 0) == False:\n",
    "        print('No data exists in ' + col_name + ' the entity file.')\n",
    "    \n",
    "def member_id_creator(member_file_path, col_name):\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    if (len(member_file[col_name].dropna()) > 0) == True:\n",
    "        member_descriptions = member_file[col_name].unique().tolist()\n",
    "        print('Data exists in ' + col_name + ' for the membership file.')\n",
    "        return pd.DataFrame({col_name : member_descriptions}) \n",
    "    else:\n",
    "        print('No data exists in ' + col_name + ' for the membership file.')\n",
    "    \n",
    "def clean(df,col_name):\n",
    "    df[col_name+'_clean'] = df[col_name]\n",
    "    df[col_name+'_clean'].replace('\\d+', '', regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\(', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\)', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Elem Sch', 'Elementary',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High School', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Middle Sch', 'MS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High Sch', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'] = df[col_name+'_clean'].str.rstrip(' ')\n",
    "    return df\n",
    "\n",
    "def matcher(member_file_path, entity_file_path, member_entity_category_tuple):        \n",
    "    mem_name = member_entity_category_tuple[0]\n",
    "    enti_name_list = re.findall('[A-Z][^A-Z]*', member_entity_category_tuple[1])\n",
    "    enti_name = ' '.join(enti_name_list) + ' Name'\n",
    "    enti_id = ' '.join(enti_name_list) + ' Id'\n",
    "    member = member_id_creator(member_file_path, mem_name)\n",
    "    entity = entity_file_creator(entity_file_path, member_entity_category_tuple[1])\n",
    "    \n",
    "    member = clean(member, mem_name)\n",
    "    \n",
    "    cleaned_mem_name = mem_name+'_clean'\n",
    "    \n",
    "    perf_matches = member.merge(entity, how='inner', left_on=cleaned_mem_name, right_on=enti_name)\n",
    "    member_wo_perf_matches = member[~member[mem_name].isin(perf_matches[mem_name])]\n",
    "    entity_wo_perf_matches = entity[~entity[enti_id].isin(perf_matches[enti_id])]\n",
    "\n",
    "    #fuzzy matching\n",
    "    member_wo_perf_matches.set_index(mem_name,inplace=True)\n",
    "    entity_wo_perf_matches.set_index(enti_id,inplace=True)\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.full()\n",
    "    candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "    compare = recordlinkage.Compare()\n",
    "    compare.string(cleaned_mem_name,enti_name,threshold=0.6,label='similarity')\n",
    "    features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "    potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "\n",
    "    entity_lu = entity_wo_perf_matches[[enti_name]].reset_index()\n",
    "    member_lu = member_wo_perf_matches[[cleaned_mem_name]].reset_index()\n",
    "    entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "    fuzzy_matches = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "    \n",
    "    if len(perf_matches) !=  0:\n",
    "        perf_matches['type'] = ['Perfect Match']*len(perf_matches)\n",
    "    if len(fuzzy_matches) !=  0:\n",
    "        fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == False, 'type'] = 'One-to-One Fuzzy Match'\n",
    "        fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == True, 'type'] = 'Multiple Fuzzy Matches'\n",
    "        fuzzy_matches.loc[fuzzy_matches[enti_id].isna(), 'type'] = 'No Match to Entity File Found'\n",
    "    \n",
    "    concat = pd.concat([fuzzy_matches,perf_matches])\n",
    "    return concat\n",
    "\n",
    "categories = [('JobDescription','JobTitle'),('LocalJobClassName','LocalJobClass'),('WorkLocationName','WorkLocation'),('WorkStructureName','WorkStructure')]\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\Desktop\\files\\entity_file_fuzzy_match\\testing_locals\"\n",
    "        \n",
    "pathlist = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist:\n",
    "    member_file_path = path\n",
    "    print(path)\n",
    "    #put limit here so only knackbuild files with correct str length get processed? prevent possible errors/bugs?\n",
    "    entity_file_path = str(path)[:-24] + 'Entity.xlsx'\n",
    "    entity_file_path = Path(entity_file_path)\n",
    "    for category in categories:\n",
    "        try:\n",
    "            match = matcher(member_file_path, entity_file_path, category)\n",
    "            match.to_csv(str(path)[:-24] + \"{}_match.csv\".format(category[0]),index=False)\n",
    "            print('Fuzzy match spreadsheet created.')\n",
    "        except TypeError as te:\n",
    "            print(str(te) + \" Spreadsheet not created.\")\n",
    "        except FileNotFoundError:\n",
    "            print('Entity file does not exist. Spreadsheet not created.')\n",
    "        #except ValueError:\n",
    "        #    print('No data exists in {} in the entity file. A spreadsheet of matches between the entity and membership file will not be created.'.format(category[1]))\n",
    "        except KeyError as ke:\n",
    "            print(str(ke))\n",
    "        #except:\n",
    "        #    print('TESTING TESTING TESTING')\n",
    "        #    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
