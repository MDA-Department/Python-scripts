{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abbd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import urllib.parse\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "class KnackAFT:\n",
    "    def __init__(self):\n",
    "        # API #\n",
    "        self.API_VERSION = 'v1'\n",
    "        self.API_KEY = '1a210580-315e-11ea-a6a4-bb031a9e1ba1'\n",
    "        self.APP_ID = '5e13989941e72c0e039e117f'\n",
    "        self.CUSTOM_KNACK_ENDPOINT = 'knack.aft.org'\n",
    "        \n",
    "        # HTTP REQUESTS #\n",
    "        self.GET_HEADERS = {'X-Knack-REST-API-KEY':self.API_KEY,'X-Knack-Application-Id':self.APP_ID}\n",
    "        self.POST_HEADERS = {'X-Knack-REST-API-KEY':self.API_KEY,'X-Knack-Application-Id':self.APP_ID,'content-type':'application/json'}\n",
    "        self.API_URL = f'https://api.{self.CUSTOM_KNACK_ENDPOINT}/{self.API_VERSION}/'\n",
    "        self.LOADER_URL = f'https://loader.{self.CUSTOM_KNACK_ENDPOINT}/{self.API_VERSION}/applications/{self.APP_ID}'\n",
    "\n",
    "        # INTERNAL #\n",
    "        self.APP_DICT = {}\n",
    "\n",
    "        \n",
    "    # function to return key for any value\n",
    "    def get_key(self, dictionary ,val):\n",
    "        for key, value in dictionary.items():\n",
    "            if val == value:\n",
    "                return key\n",
    "\n",
    "        return ''\n",
    "    \n",
    "    def loader(self):\n",
    "        res = requests.get(url=self.LOADER_URL)\n",
    "        objects = res.json()['application']['objects']\n",
    "\n",
    "        for obj in objects:\n",
    "            fields = {}\n",
    "            name = obj['name']\n",
    "            key = obj['key']\n",
    "\n",
    "            if 'Entity-' in name:\n",
    "                for item in obj['fields']:\n",
    "                    fields.update({item['name']:item['key']})\n",
    "                self.APP_DICT.update({name.replace('Entity-', ''):{'id':key,'fields':fields}})\n",
    "    \n",
    "    # JSON PRINT HELPER #\n",
    "    def jprint(output):\n",
    "        print(json.dumps(output, indent=4))\n",
    "    \n",
    "    # GET and format json from requestURL\n",
    "    def getJSON(self, url):\n",
    "        r = requests.get(url = self.API_URL + url, headers = self.GET_HEADERS)\n",
    "        return r.json()\n",
    "    \n",
    "    def getObjectJSON(self, object_name):\n",
    "        return (self.getJSON('objects/' + self.APP_DICT[object_name]['id']))['object']\n",
    "        \n",
    "    def find_matches(self, object_name, field_name, match_val, multi=False):\n",
    "        field_id = self.APP_DICT[object_name]['fields'][field_name]\n",
    "        object_id = self.APP_DICT[object_name]['id']\n",
    "        \n",
    "        match_filter = {'match':'and', 'rules':[{'field':field_id, 'operator':'is', 'value': match_val}]}\n",
    "        filter_for_url = urllib.parse.quote(json.dumps(match_filter))\n",
    "        request_url = \"objects/\" + object_id + \"/records?filters=\" + filter_for_url\n",
    "        res = self.getJSON(request_url)\n",
    "        if res[\"total_records\"] == 0:\n",
    "            return ''\n",
    "        elif res[\"total_records\"] == 1:\n",
    "            return res[\"records\"]\n",
    "        else:\n",
    "            if multi:\n",
    "                return res[\"records\"]\n",
    "            else:\n",
    "                return ''\n",
    "            \n",
    "    def convert_fields_ids2name(self, object_name, ids):\n",
    "        field_dict = self.APP_DICT[object_name]['fields']\n",
    "        out_dict = {}\n",
    "        \n",
    "        for k, v in ids.items():\n",
    "            if 'field' in k:\n",
    "                if 'raw' in k:\n",
    "                    newk = k.replace('_raw', '')\n",
    "                    key = self.get_key(field_dict, newk)\n",
    "                    if key:\n",
    "                        out_dict.update({(key+'_raw'):v})\n",
    "                    else:\n",
    "                        out_dict.update({k:v})\n",
    "                else:\n",
    "                    key = self.get_key(field_dict, k)\n",
    "                    if key:\n",
    "                        out_dict.update({key:v})\n",
    "                    else:\n",
    "                        out_dict.update({k:v})\n",
    "            else:\n",
    "                out_dict.update({k:v})\n",
    "        return out_dict\n",
    "    \n",
    "    def convert_fields_name2ids(self, object_name, names):\n",
    "        DICT = {}\n",
    "        out = {}\n",
    "        for k,v in self.APP_DICT[object_name]['fields'].items():\n",
    "            DICT.update({k.lower():v})\n",
    "        for k, v in names.items():\n",
    "            key = DICT[k]\n",
    "            out.update({key:v})\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running file:- Export_Full_Results_0000_part_00_combine-3.csv\n",
      "---INFO---\n",
      "Number of lines present:- 113347\n",
      "Running in batch size:- 500\n",
      "Total batches:- 227\n",
      "----------\n",
      "Running batch:- 1\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL VARIABLES #\n",
    "FILE_INPUT = 'Export_Full_Results_0000_part_00_combine-3.csv'\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "# MAIN LOGIC #\n",
    "client = KnackAFT()\n",
    "client.loader()\n",
    "\n",
    "connections = ['nationaljobclassid', 'unitid', 'affiliateid']\n",
    "connections_fields = ['field_341', 'field_342', 'field_591']\n",
    "\n",
    "DICT = client.APP_DICT['LocalJobClass']['fields']\n",
    "runnerDICT = {k.lower(): v for k, v in DICT.items()}\n",
    "\n",
    "#jprint(client.APP_DICT['Affiliate'])\n",
    "\n",
    "def uploader(payload):\n",
    "    request_url = \"https://api.knack.aft.org/v1/objects/object_21/records\"\n",
    "    return requests.post(url = request_url, headers = client.POST_HEADERS, data = json.dumps(payload))\n",
    "    \n",
    "\n",
    "def getIds(arg, val):\n",
    "    if arg == 'nationaljobclassid':\n",
    "        return \n",
    "    if arg == 'unitid':\n",
    "        return client.find_matches('Unit', 'UnitId', val)\n",
    "    if arg == 'affiliateid':\n",
    "        return client.find_matches('Affiliate', 'AffiliateID', val)\n",
    "\n",
    "\n",
    "def processCSV():\n",
    "    GLOBAL_NJC_CACHE ={}\n",
    "    GLOBAL_UNIT_CACHE ={}\n",
    "    GLOBAL_AFF_CACHE ={}\n",
    "    \n",
    "    # Entity Dict\n",
    "    DICT = {}\n",
    "    for k,v in client.APP_DICT['LocalJobClass']['fields'].items():\n",
    "        DICT.update({k.lower():v})\n",
    "    \n",
    "    # read and format CSV file\n",
    "    print('Running file:-', FILE_INPUT)\n",
    "    \n",
    "    df = pd.read_csv(FILE_INPUT, quoting=csv.QUOTE_ALL, converters={i: str for i in range(0, 100)})\n",
    "    df.fillna('', inplace = True)\n",
    "    for col in df.columns:\n",
    "        if col in connections:\n",
    "            df.rename(columns={col:('entity-' + col.replace('id', ''))}, inplace=True)\n",
    "    for col in df.columns:\n",
    "        new_col = DICT[col]\n",
    "        df.rename(columns={col:new_col}, inplace=True)\n",
    "    \n",
    "    print('---INFO---')\n",
    "    print(\"Number of lines present:-\", len(df))\n",
    "    print(\"Running in batch size:-\", BATCH_SIZE)\n",
    "    print('Total batches:-' , math.ceil(len(df)/BATCH_SIZE))\n",
    "    print('----------')\n",
    "    \n",
    "    #split into DataFrames\n",
    "    batch_count = 0\n",
    "    \n",
    "    while batch_count < math.ceil(len(df)/BATCH_SIZE):\n",
    "        mem_df = {}\n",
    "        if batch_count == 0:\n",
    "            mem_df = df.iloc[:BATCH_SIZE].copy()\n",
    "        else:\n",
    "            mem_df = df.iloc[(BATCH_SIZE*batch_count):(BATCH_SIZE*(batch_count+1))].copy()\n",
    "        batch_count += 1\n",
    "        print('Running batch:-' , batch_count)\n",
    "\n",
    "        # Get NationalJobClass Connection\n",
    "        for index, val in mem_df['field_341'].items():\n",
    "            if val:\n",
    "                if val in GLOBAL_NJC_CACHE:\n",
    "                    mem_df.loc[0:index,'field_341'] = GLOBAL_NJC_CACHE[val]\n",
    "                else:\n",
    "                    idreturned = client.find_matches('NationalJobClass', 'NationalJobClassId', val)[0]['id']\n",
    "                    mem_df.loc[0:index,'field_341'] = idreturned\n",
    "                    GLOBAL_NJC_CACHE.update({val:idreturned})\n",
    "\n",
    "\n",
    "        # Get Unit Connection\n",
    "        for index, val in mem_df['field_342'].items():\n",
    "            if val:\n",
    "                if val in GLOBAL_UNIT_CACHE.keys():\n",
    "                    mem_df.loc[0:index,'field_342'] = GLOBAL_UNIT_CACHE[val]\n",
    "                else:\n",
    "                    idreturned = client.find_matches('Unit', 'UnitId', val)[0]['id']\n",
    "                    mem_df.loc[0:index,'field_342'] = idreturned\n",
    "                    GLOBAL_UNIT_CACHE.update({val:idreturned})\n",
    "\n",
    "\n",
    "        # Get Aff Connection\n",
    "        for index, val in mem_df['field_591'].items():\n",
    "            if val:\n",
    "                if val in GLOBAL_AFF_CACHE.keys():\n",
    "                    mem_df.loc[0:index,'field_591'] = GLOBAL_AFF_CACHE[val]\n",
    "                else:\n",
    "                    idreturned = client.find_matches('Affiliate', 'AffiliateID', val)[0]['id']\n",
    "                    mem_df.loc[0:index,'field_591'] = idreturned\n",
    "                    GLOBAL_AFF_CACHE.update({val:idreturned})\n",
    "                    \n",
    "                    \n",
    "        payload_list = mem_df.to_dict('records')\n",
    "        count = 0\n",
    "        for payload in payload_list:\n",
    "            count += 1\n",
    "            r = uploader(payload)\n",
    "            if r.status_code != 200:\n",
    "                print('', end='\\n')\n",
    "                print(payload)\n",
    "                print(json.dumps(r.json(), indent=4))\n",
    "                print('Error on line: ', (batch_count-1)*BATCH_SIZE+count+1, ' of CSV input file')\n",
    "                batch_count = 9999999999999\n",
    "                break\n",
    "            else:\n",
    "                print('Row:-', count, '/', len(payload_list), ':', r, end='\\r')\n",
    "        print('', end='\\n')\n",
    "        print('Batch Done!')\n",
    "        print('----------')\n",
    "    print('Input File Done!')\n",
    "processCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8429fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea50e146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement yaml (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for yaml\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.1.14_1/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6ddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
