{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa356670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def entity_file_creator(entity_file_path, ws_name):\n",
    "    entity_sheet = pd.read_excel(entity_file_path, ws_name)\n",
    "    col_name_list = re.findall('[A-Z][^A-Z]*', ws_name)\n",
    "    col_name = ' '.join(col_name_list) + ' Name'\n",
    "    if (len(entity_sheet[col_name].dropna()) > 0) == True:\n",
    "        col_id = ' '.join(col_name_list) + ' Id'\n",
    "        data = {col_name : entity_sheet[col_name].str.rstrip(), col_id: entity_sheet[col_id]}\n",
    "        \n",
    "        return pd.DataFrame(data).dropna()    \n",
    "    \n",
    "def member_id_creator(member_file_path, col_name):\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    if (len(member_file[col_name].dropna()) > 0) == True:\n",
    "        unique_entries_index = member_file[col_name].drop_duplicates().index\n",
    "        member_descriptions = member_file.loc[unique_entries_index, col_name].values\n",
    "        data = {col_name:member_descriptions}\n",
    "            \n",
    "        return pd.DataFrame(data) \n",
    "    \n",
    "def clean(df,col_name):\n",
    "    df[col_name+'_clean'] = df[col_name]\n",
    "    df[col_name+'_clean'].replace('\\d+', '', regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\(', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('\\)', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Elem Sch', 'Elementary',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High School', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Middle Sch', 'MS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High Sch', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'] = df[col_name+'_clean'].str.rstrip(' ')\n",
    "    return df\n",
    "\n",
    "def matcher(member_file_path, entity_file_path, member_entity_category_tuple):        \n",
    "    mem_name = member_entity_category_tuple[0]\n",
    "    enti_name_list = re.findall('[A-Z][^A-Z]*', member_entity_category_tuple[1])\n",
    "    enti_name = ' '.join(enti_name_list) + ' Name'\n",
    "    enti_id = ' '.join(enti_name_list) + ' Id'\n",
    "    member = member_id_creator(member_file_path, mem_name)\n",
    "    entity = entity_file_creator(entity_file_path, member_entity_category_tuple[1])\n",
    "    \n",
    "    if entity is not None and member is not None:\n",
    "        member = clean(member, mem_name)\n",
    "        \n",
    "        cleaned_mem_name = mem_name+'_clean'\n",
    "            \n",
    "        #perfect matching\n",
    "        perf_matches = member.merge(entity, how='inner', left_on=cleaned_mem_name, right_on=enti_name)\n",
    "        member_wo_perf_matches = member[~member[mem_name].isin(perf_matches[mem_name])]\n",
    "        entity_wo_perf_matches = entity[~entity[enti_id].isin(perf_matches[enti_id])]\n",
    "\n",
    "        #fuzzy matching\n",
    "        member_wo_perf_matches.set_index(mem_name,inplace=True)\n",
    "        entity_wo_perf_matches.set_index(enti_id,inplace=True)\n",
    "        indexer = recordlinkage.Index()\n",
    "        indexer.full()\n",
    "        candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "        compare = recordlinkage.Compare()\n",
    "        compare.string(cleaned_mem_name,enti_name,threshold=0.6,label='similarity')\n",
    "        features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "        potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "\n",
    "        entity_lu = entity_wo_perf_matches[[enti_name]].reset_index()\n",
    "        member_lu = member_wo_perf_matches[[cleaned_mem_name]].reset_index()\n",
    "        entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "        fuzzy_matches = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "        fuzzy_matches = fuzzy_matches.dropna(subset=[mem_name],axis=0)\n",
    "    \n",
    "        if len(perf_matches) !=  0: perf_matches['type'] = ['Perfect Match']*len(perf_matches) \n",
    "        if len(fuzzy_matches) !=  0:\n",
    "            fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == False, 'type'] = 'One-to-One Fuzzy Match'\n",
    "            fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == True, 'type'] = 'Multiple Fuzzy Matches'\n",
    "            fuzzy_matches.loc[fuzzy_matches[enti_id].isna(), 'type'] = 'No Match to Entity File Found'\n",
    "        fuzzy_matches.to_csv(str(member_file_path)[:-24] + \"{}_fuzzymatch.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        concat = pd.concat([fuzzy_matches,perf_matches])\n",
    "        #print(str(member_file_path)[:-24])\n",
    "        concat.to_csv(str(member_file_path)[:-24] + \"{}_match.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        print('Both membership and entity file data exist for {}. Fuzzy match spreadsheet created.'.format(member_entity_category_tuple))\n",
    "    elif entity is None and member is not None:\n",
    "        member.to_csv(str(member_file_path)[:-24] + \"{}_member.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        print('The membership file data exists for {} but entity file data does not.'.format(member_entity_category_tuple))\n",
    "        print('A spreadsheet of entries in the membership file has been created.')\n",
    "        print('The affiliate may need to be contacted to create entity file categories.')\n",
    "    elif entity is not None and member is None:\n",
    "        print('The entity file data exists for {} but membership file data does not.'.format(member_entity_category_tuple))\n",
    "        print('No spreadsheet created.')\n",
    "    else:\n",
    "        print('Neither membership nor entity file data exists.')\n",
    "        print('No spreadsheet created.')\n",
    "        \n",
    "\n",
    "categories = [('JobTitleName','JobTitle'),('LocalJobClassName','LocalJobClass'),('WorkLocationName','WorkLocation'),('WorkStructureName','WorkStructure')]\n",
    "\n",
    "directory = r\"C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\"\n",
    "        \n",
    "pathlist = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist:\n",
    "    member_file_path = path\n",
    "    print(path)\n",
    "    #put limit here so only knackbuild files with correct str length get processed? prevent possible errors/bugs?\n",
    "    entity_file_path = str(path)[:-30] + 'EntityList.xlsx'\n",
    "    entity_file_path = Path(entity_file_path)\n",
    "    for category in categories:\n",
    "        #try:\n",
    "        matcher(member_file_path, entity_file_path, category)\n",
    "        #except:\n",
    "        #    print('Error')\n",
    "        #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc507e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\\04100_XXXXX\\04100_XXXXX_JobTitleName_match.csv\n",
      "C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\\04100_XXXXX\\04100_XXXXX_LocalJobClassName_match.csv\n",
      "C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\\05221_XXXXX\\05221_XXXXX_JobTitleName_match.csv\n",
      "C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\\05221_XXXXX\\05221_XXXXX_LocalJobClassName_match.csv\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\AFT\\\\OneDrive - aft.org\\\\Fuzzymatcher\\\\testing_locals\\\\05221_XXXXX\\\\05221_XXXXX_XXXXXXXX_Knackbuild_w_entityids.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-827ff0dc8aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmerged_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch_col_spaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_col_id_spaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_col_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_clean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#drop match_col_spaces + match_col_id_spaces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmerged_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2187\u001b[0m             \u001b[0minf_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2188\u001b[0m         )\n\u001b[1;32m-> 2189\u001b[1;33m         formatter.write(\n\u001b[0m\u001b[0;32m   2190\u001b[0m             \u001b[0mexcel_writer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    813\u001b[0m             \u001b[1;31m# abstract class 'ExcelWriter' with abstract attributes 'engine',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[1;31m# 'save', 'supported_extensions' and 'write_cells'  [abstract]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m             writer = ExcelWriter(  # type: ignore[abstract]\n\u001b[0m\u001b[0;32m    816\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, **engine_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Append mode is not supported with xlsxwriter!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         super().__init__(\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, **engine_kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIOHandles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"copression\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m    811\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\AFT\\\\OneDrive - aft.org\\\\Fuzzymatcher\\\\testing_locals\\\\05221_XXXXX\\\\05221_XXXXX_XXXXXXXX_Knackbuild_w_entityids.xlsx'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "directory = r\"C:\\Users\\AFT\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\"\n",
    "\n",
    "#creating new copy of membership file to work in so original file is preserved\n",
    "pathlist_knackbuild = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist_knackbuild:\n",
    "    shutil.copy(path, str(path)[:-5] + '_w_entityids.xlsx')\n",
    "\n",
    "pathlist_fuzzymatch = Path(directory).glob('**/*_match.csv')\n",
    "for path in pathlist_fuzzymatch:\n",
    "    print(path)\n",
    "    fuzzy_match_file = pd.read_csv(path)\n",
    "    member_file_path = list(Path(str(path)[0:71]).glob('**/*Knackbuild_w_entityids.xlsx'))[0]\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    \n",
    "    match_col_name = str(path).split(\"_\")[4]\n",
    "    merged_file = member_file.merge(fuzzy_match_file, on = match_col_name, how='left')\n",
    "    \n",
    "    match_col_name_list = re.findall('[A-Z][^A-Z]*', match_col_name) #creating vars for id with spaces and id without spaces\n",
    "    match_col_spaces = ' '.join(match_col_name_list) #creating var for name without spaces\n",
    "    match_col_name_list.remove('Name')\n",
    "    match_col_id_spaces = ' '.join(match_col_name_list) + ' Id'\n",
    "    match_col_id_no_spaces = ''.join(match_col_name_list) + 'Id'  \n",
    "    merged_file[match_col_name] = merged_file[match_col_spaces]\n",
    "    merged_file[match_col_id_no_spaces] = merged_file[match_col_id_spaces] \n",
    "    merged_file.drop([match_col_spaces, match_col_id_spaces, match_col_name + \"_clean\", \"type\"],axis=1,inplace=True)  #drop match_col_spaces + match_col_id_spaces\n",
    "    \n",
    "    merged_file.to_excel(member_file_path,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd54707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
