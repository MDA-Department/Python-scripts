{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568a0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import recordlinkage\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def entity_file_creator(entity_file_path, ws_name):\n",
    "    entity_sheet = pd.read_excel(entity_file_path, ws_name)\n",
    "    col_name_list = re.findall('[A-Z][^A-Z]*', ws_name)\n",
    "    col_name = ' '.join(col_name_list) + ' Name'\n",
    "    if (len(entity_sheet[col_name].dropna()) > 0) == True:\n",
    "        col_id = ' '.join(col_name_list) + ' Id'\n",
    "        data = {col_name : entity_sheet[col_name].str.rstrip(), col_id: entity_sheet[col_id]}\n",
    "        if ws_name == 'JobTitle' or ws_name == 'LocalJobClass': \n",
    "            if ((len(entity_sheet['Unit Name'].dropna()) > 0) == True): \n",
    "                data['Unit Name'] = entity_sheet['Unit Name'].values   \n",
    "        elif ws_name == 'WorkLocation' or ws_name == 'WorkStructure': \n",
    "            if ((len(entity_sheet['Employer Name'].dropna()) > 0) == True): \n",
    "                data['Employer Name'] = entity_sheet['Employer Name'].values   \n",
    "        return pd.DataFrame(data).dropna()    \n",
    "    \n",
    "def member_id_creator(member_file_path, col_name):\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    if (len(member_file[col_name].dropna()) > 0) == True:\n",
    "        block_type = ''\n",
    "        if col_name == 'JobTitleName' or col_name == 'LocalJobClassName': \n",
    "            block_type = 'UnitName'\n",
    "        elif col_name == 'WorkLocationName' or col_name == 'WorkStructureName':\n",
    "            block_type = 'EmployerName'\n",
    "        col_and_units_name = str(col_name) + \" + \" + block_type\n",
    "        member_file[col_and_units_name] = member_file[col_name].astype(str) + member_file[block_type].astype(str)\n",
    "        unique_entries_index = member_file[col_and_units_name].drop_duplicates().index\n",
    "        member_descriptions = member_file.loc[unique_entries_index, col_name].values\n",
    "        units = member_file.loc[unique_entries_index, block_type].values\n",
    "        descriptions_and_units = member_file.loc[unique_entries_index, col_and_units_name].values\n",
    "        data = {col_name:member_descriptions, block_type:units, col_and_units_name:descriptions_and_units}\n",
    "        return pd.DataFrame(data) \n",
    "    \n",
    "    \n",
    "def clean(df,col_name):\n",
    "    df[col_name+'_clean'] = df[col_name]\n",
    "    df[col_name+'_clean'].replace('\\d+', '', regex=True,inplace=True)\n",
    "    #df[col_name+'_clean'].replace('\\(', '',regex=True,inplace=True)\n",
    "    #df[col_name+'_clean'].replace('\\)', '',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Elem Sch', 'Elementary',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High School', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('Middle Sch', 'MS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'].replace('High Sch', 'HS',regex=True,inplace=True)\n",
    "    df[col_name+'_clean'] = df[col_name+'_clean'].str.rstrip(' ')\n",
    "    return df\n",
    "\n",
    "\n",
    "def matcher(member_file_path, entity_file_path, member_entity_category_tuple):        \n",
    "    mem_name = member_entity_category_tuple[0]\n",
    "    enti_name_list = re.findall('[A-Z][^A-Z]*', member_entity_category_tuple[1])\n",
    "    enti_name = ' '.join(enti_name_list) + ' Name'\n",
    "    enti_id = ' '.join(enti_name_list) + ' Id'\n",
    "    member = member_id_creator(member_file_path, mem_name)\n",
    "    entity = entity_file_creator(entity_file_path, member_entity_category_tuple[1])\n",
    "    block_type = ''\n",
    "    block_type_spaces = ''\n",
    "    if mem_name == 'JobTitleName' or mem_name == 'LocalJobClassName': \n",
    "        block_type = 'UnitName'\n",
    "        block_type_spaces = 'Unit Name'\n",
    "    elif mem_name == 'WorkLocationName' or mem_name == 'WorkStructureName':\n",
    "        block_type = 'EmployerName'\n",
    "        block_type_spaces = 'Employer Name'\n",
    "    \n",
    "    if entity is not None and member is not None:\n",
    "        member = clean(member, mem_name)\n",
    "        cleaned_mem_name = mem_name+'_clean'\n",
    "\n",
    "        if (block_type in member.columns) and (block_type_spaces in entity.columns):\n",
    "            #perfect matching\n",
    "            perf_matches = member.merge(entity, how='inner', left_on=[cleaned_mem_name, block_type], right_on=[enti_name, block_type_spaces])\n",
    "            member_wo_perf_matches = member[~member[mem_name + \" + \" + block_type].isin(perf_matches[mem_name + \" + \" + block_type])]\n",
    "            entity_wo_perf_matches = entity[~entity[enti_id].isin(perf_matches[enti_id])]\n",
    "            \n",
    "            #fuzzy matching\n",
    "            member_wo_perf_matches.set_index(mem_name + \" + \" + block_type,inplace=True)\n",
    "            entity_wo_perf_matches.set_index(enti_id,inplace=True)\n",
    "            indexer = recordlinkage.Index()\n",
    "            indexer.block(left_on=block_type, right_on=block_type_spaces)\n",
    "            candidates = indexer.index(member_wo_perf_matches, entity_wo_perf_matches)\n",
    "            compare = recordlinkage.Compare()\n",
    "            compare.string(cleaned_mem_name,enti_name,threshold=0.6,label='similarity')\n",
    "            features = compare.compute(candidates, member_wo_perf_matches, entity_wo_perf_matches)\n",
    "            potential_matches = features[features.sum(axis=1) == 1].reset_index()\n",
    "\n",
    "            entity_lu = entity_wo_perf_matches[[enti_name, block_type_spaces]].reset_index()\n",
    "            member_lu = member_wo_perf_matches[[cleaned_mem_name, mem_name, block_type]].reset_index()\n",
    "            entity_merge = potential_matches.merge(entity_lu, how='outer')\n",
    "            fuzzy_matches = entity_merge.merge(member_lu, how='right').drop(['similarity'],axis=1)\n",
    "    \n",
    "            if len(perf_matches) !=  0: perf_matches['type'] = ['Perfect Match']*len(perf_matches) \n",
    "            if len(fuzzy_matches) !=  0:\n",
    "                fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == False, 'type'] = 'One-to-One Fuzzy Match'\n",
    "                fuzzy_matches.loc[fuzzy_matches[mem_name].duplicated(keep=False) == True, 'type'] = 'Multiple Fuzzy Matches'\n",
    "                fuzzy_matches.loc[fuzzy_matches[enti_id].isna(), 'type'] = 'No Match to Entity File Found'\n",
    "    \n",
    "            concat = pd.concat([fuzzy_matches,perf_matches]).sort_values(by=['type'])\n",
    "            concat.to_csv(str(member_file_path)[:-24] + \"{}_match.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "            print('Both membership and entity file data exist for {}. Fuzzy match spreadsheet created.'.format(member_entity_category_tuple))\n",
    "            print('WARNING: This local has multiple units. Match carefully.')\n",
    "        else:\n",
    "            print('ERROR: {} data does not exist in both the entity and membership file but it should.'.format(block_type))\n",
    "            print('Clean file and try again.')\n",
    "                \n",
    "    elif entity is None and member is not None:\n",
    "        member.to_csv(str(member_file_path)[:-24] + \"{}_member.csv\".format(member_entity_category_tuple[0]),index=False)\n",
    "        print('The membership file data exists for {} but entity file data does not.'.format(member_entity_category_tuple))\n",
    "        print('A spreadsheet of entries in the membership file has been created.')\n",
    "        print('The affiliate may need to be contacted to create entity file categories.')\n",
    "    elif entity is not None and member is None:\n",
    "        print('The entity file data exists for {} but membership file data does not.'.format(member_entity_category_tuple))\n",
    "        print('No spreadsheet created.')\n",
    "    else:\n",
    "        print('Neither membership nor entity file data exists.')\n",
    "        print('No spreadsheet created.')\n",
    "        \n",
    "\n",
    "categories = [('JobTitleName','JobTitle'),('LocalJobClassName','LocalJobClass'),('WorkLocationName','WorkLocation'),('WorkStructureName','WorkStructure')]\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\"\n",
    "        \n",
    "pathlist = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist:\n",
    "    member_file_path = path\n",
    "    print(path)\n",
    "    entity_file_path = str(path)[:-30] + 'EntityList.xlsx'\n",
    "    print(entity_file_path)\n",
    "    entity_file_path = Path(entity_file_path)\n",
    "    for category in categories:\n",
    "        #try:\n",
    "        matcher(member_file_path, entity_file_path, category)\n",
    "        #except:\n",
    "         #   print('Error')\n",
    "          #  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f6660",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "directory = r\"C:\\Users\\pgoktas\\OneDrive - aft.org\\Fuzzymatcher\\testing_locals\"\n",
    "\n",
    "#creating new copy of membership file to work in so original file is preserved\n",
    "pathlist_knackbuild = Path(directory).glob('**/*Knackbuild.xlsx')\n",
    "for path in pathlist_knackbuild:\n",
    "    shutil.copy(path, str(path)[:-5] + '_w_entityids.xlsx')\n",
    "\n",
    "pathlist_fuzzymatch = Path(directory).glob('**/*_match.csv')\n",
    "for path in pathlist_fuzzymatch:\n",
    "    print(path)\n",
    "    fuzzy_match_file = pd.read_csv(path)\n",
    "    member_file_path = list(Path(str(path)[0:75]).glob('**/*Knackbuild_w_entityids.xlsx'))[0]\n",
    "    member_file = pd.read_excel(member_file_path)\n",
    "    \n",
    "    match_col_name = str(path).split(\"_\")[4]\n",
    "    block_type = ''\n",
    "    if match_col_name == 'JobTitleName' or match_col_name == 'LocalJobClassName': \n",
    "        block_type = 'UnitName'\n",
    "        block_type_spaces = 'Unit Name'\n",
    "    elif match_col_name == 'WorkLocationName' or match_col_name == 'WorkStructureName':\n",
    "        block_type = 'EmployerName'\n",
    "        block_type_spaces = 'Employer Name'\n",
    "    col_and_units_name = str(match_col_name) + \" + \" + block_type    \n",
    "    member_file[col_and_units_name] = member_file[match_col_name] + member_file[block_type]\n",
    "    fuzzy_match_file.drop([block_type,'type',match_col_name,match_col_name + \"_clean\",block_type_spaces],axis=1,inplace=True)\n",
    "    merged_file = member_file.merge(fuzzy_match_file, on = col_and_units_name, how='left')\n",
    "    \n",
    "    match_col_name_list = re.findall('[A-Z][^A-Z]*', match_col_name)\n",
    "    match_col_spaces = ' '.join(match_col_name_list) #creating var for name with spaces\n",
    "    match_col_name_list.remove('Name')\n",
    "    match_col_id_spaces = ' '.join(match_col_name_list) + ' Id'\n",
    "    match_col_id_no_spaces = ''.join(match_col_name_list) + 'Id'\n",
    "    merged_file.drop([match_col_name,col_and_units_name],axis=1,inplace=True)\n",
    "    merged_file.rename(columns={match_col_spaces:match_col_name,match_col_id_spaces:match_col_id_no_spaces},inplace=True)\n",
    "        \n",
    "    merged_file.to_excel(member_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c5418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
