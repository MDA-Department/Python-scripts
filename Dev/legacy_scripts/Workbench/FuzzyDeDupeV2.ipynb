{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d3744d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Total xlsx files found: 1\n",
      "Starting file 1/1: file_run.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Index</th>\n",
       "      <th>Match</th>\n",
       "      <th>|</th>\n",
       "      <th>Index-Full Name</th>\n",
       "      <th>Match-Full Name</th>\n",
       "      <th>|</th>\n",
       "      <th>Index-Address Line1</th>\n",
       "      <th>Match-Address Line1</th>\n",
       "      <th>|</th>\n",
       "      <th>Index-Home Email</th>\n",
       "      <th>Match-Home Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>2</td>\n",
       "      <td>1565</td>\n",
       "      <td>1312</td>\n",
       "      <td></td>\n",
       "      <td>Kyle Miller</td>\n",
       "      <td>Kyle Miller</td>\n",
       "      <td></td>\n",
       "      <td>1666 32nd St NW</td>\n",
       "      <td>1666 32nd St NW</td>\n",
       "      <td></td>\n",
       "      <td>kaugmiller@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>2</td>\n",
       "      <td>1355</td>\n",
       "      <td>882</td>\n",
       "      <td></td>\n",
       "      <td>Amjad Ali Alqahtani</td>\n",
       "      <td>Amjad Ali Alqahtani</td>\n",
       "      <td></td>\n",
       "      <td>4547 Indian Rock Ter NW</td>\n",
       "      <td>4547 Indian Rock Ter NW</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2</td>\n",
       "      <td>1538</td>\n",
       "      <td>1339</td>\n",
       "      <td></td>\n",
       "      <td>Sarena Noelani Young</td>\n",
       "      <td>Sarena Noelani Young</td>\n",
       "      <td></td>\n",
       "      <td>1707 N Troy St</td>\n",
       "      <td>1707 N Troy St</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>2</td>\n",
       "      <td>1424</td>\n",
       "      <td>1393</td>\n",
       "      <td></td>\n",
       "      <td>Helena Cristina Dill</td>\n",
       "      <td>Helena Cristina Dill</td>\n",
       "      <td></td>\n",
       "      <td>2425 L ST NW</td>\n",
       "      <td>2425 L ST NW</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>hcd17@georgetown.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>2</td>\n",
       "      <td>1781</td>\n",
       "      <td>1765</td>\n",
       "      <td></td>\n",
       "      <td>Ali Marhoon</td>\n",
       "      <td>Ali Marhoon</td>\n",
       "      <td></td>\n",
       "      <td>1800 N Lynn St</td>\n",
       "      <td>1800 N Lynn St</td>\n",
       "      <td></td>\n",
       "      <td>aam261@georgetown.edu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1</td>\n",
       "      <td>1376</td>\n",
       "      <td>783</td>\n",
       "      <td></td>\n",
       "      <td>John Robert Pruett</td>\n",
       "      <td>Kyu Lee</td>\n",
       "      <td></td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td></td>\n",
       "      <td>jrp157@georgetown.edu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1</td>\n",
       "      <td>1376</td>\n",
       "      <td>770</td>\n",
       "      <td></td>\n",
       "      <td>John Robert Pruett</td>\n",
       "      <td>Margaret Jacqueline Hendricks</td>\n",
       "      <td></td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td></td>\n",
       "      <td>jrp157@georgetown.edu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>1376</td>\n",
       "      <td>405</td>\n",
       "      <td></td>\n",
       "      <td>John Robert Pruett</td>\n",
       "      <td>Danielle Morency</td>\n",
       "      <td></td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td></td>\n",
       "      <td>jrp157@georgetown.edu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "      <td>1376</td>\n",
       "      <td>337</td>\n",
       "      <td></td>\n",
       "      <td>John Robert Pruett</td>\n",
       "      <td>Jie Cheng</td>\n",
       "      <td></td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td>1531 N Pierce St</td>\n",
       "      <td></td>\n",
       "      <td>jrp157@georgetown.edu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>1</td>\n",
       "      <td>1724</td>\n",
       "      <td>1434</td>\n",
       "      <td></td>\n",
       "      <td>Mitchell Paul Losito</td>\n",
       "      <td>Mitchell Paul Losito</td>\n",
       "      <td></td>\n",
       "      <td>1300 Belmont St NW</td>\n",
       "      <td>61 Hollow Tree Ridge Rd</td>\n",
       "      <td></td>\n",
       "      <td>mplbwp@optonline.net</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1619 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Score  Index  Match |        Index-Full Name  \\\n",
       "1536      2   1565   1312              Kyle Miller   \n",
       "1417      2   1355    882      Amjad Ali Alqahtani   \n",
       "694       2   1538   1339     Sarena Noelani Young   \n",
       "1474      2   1424   1393     Helena Cristina Dill   \n",
       "1045      2   1781   1765              Ali Marhoon   \n",
       "...     ...    ...    ... ..                   ...   \n",
       "535       1   1376    783       John Robert Pruett   \n",
       "534       1   1376    770       John Robert Pruett   \n",
       "533       1   1376    405       John Robert Pruett   \n",
       "532       1   1376    337       John Robert Pruett   \n",
       "1618      1   1724   1434     Mitchell Paul Losito   \n",
       "\n",
       "                    Match-Full Name |       Index-Address Line1  \\\n",
       "1536                    Kyle Miller             1666 32nd St NW   \n",
       "1417            Amjad Ali Alqahtani     4547 Indian Rock Ter NW   \n",
       "694            Sarena Noelani Young              1707 N Troy St   \n",
       "1474           Helena Cristina Dill                2425 L ST NW   \n",
       "1045                    Ali Marhoon              1800 N Lynn St   \n",
       "...                             ... ..                      ...   \n",
       "535                         Kyu Lee            1531 N Pierce St   \n",
       "534   Margaret Jacqueline Hendricks            1531 N Pierce St   \n",
       "533                Danielle Morency            1531 N Pierce St   \n",
       "532                       Jie Cheng            1531 N Pierce St   \n",
       "1618           Mitchell Paul Losito          1300 Belmont St NW   \n",
       "\n",
       "          Match-Address Line1 |        Index-Home Email      Match-Home Email  \n",
       "1536          1666 32nd St NW      kaugmiller@gmail.com                   NaN  \n",
       "1417  4547 Indian Rock Ter NW                       NaN                   NaN  \n",
       "694            1707 N Troy St                       NaN                   NaN  \n",
       "1474             2425 L ST NW                       NaN  hcd17@georgetown.edu  \n",
       "1045           1800 N Lynn St     aam261@georgetown.edu                   NaN  \n",
       "...                       ... ..                    ...                   ...  \n",
       "535          1531 N Pierce St     jrp157@georgetown.edu                   NaN  \n",
       "534          1531 N Pierce St     jrp157@georgetown.edu                   NaN  \n",
       "533          1531 N Pierce St     jrp157@georgetown.edu                   NaN  \n",
       "532          1531 N Pierce St     jrp157@georgetown.edu                   NaN  \n",
       "1618  61 Hollow Tree Ridge Rd      mplbwp@optonline.net                   NaN  \n",
       "\n",
       "[1619 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches found, check output file for information on duplicates\n",
      "Done running file file_run.xlsx\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "import dateutil\n",
    "import warnings\n",
    "import recordlinkage\n",
    "\n",
    "\n",
    "def runner(worksheet):\n",
    "    df = pd.read_excel(raw_file_name, index_col=False)\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.block('FirstName')\n",
    "    candidate_links = indexer.index(df)\n",
    "    \n",
    "    compare_cl = recordlinkage.Compare()\n",
    "\n",
    "    compare_cl.exact('FirstName', 'FirstName', label='FirstName')\n",
    "    compare_cl.string('LastName', 'LastName', method='jarowinkler', threshold=0.75, label='LastName')\n",
    "    \n",
    "    features = compare_cl.compute(candidate_links, df)\n",
    "    \n",
    "    #print(features.head(10))\n",
    "    matches = features[features.sum(axis=1) > 1]\n",
    "\n",
    "   # print(matches)\n",
    "    print(df)\n",
    "    \n",
    "    features.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    potential_dupes = features[features.sum(axis=1) > 1].reset_index()\n",
    "    potential_dupes['Score'] = potential_dupes.loc[:, 'FirstName':'LastName'].sum(axis=1)\n",
    "    \n",
    "    fname = []\n",
    "    lname = []\n",
    "    \n",
    "    for lev0 in potential_dupes['level_0']:\n",
    "        #potential_dupes['link1-FirstNam] = \n",
    "        indexed = df.loc[[lev0]]\n",
    "        fname.append(indexed['FirstName'].values[0])\n",
    "        lname.append(indexed['LastName'].values[0])\n",
    "        \n",
    "        #potential_dupes.loc[[lev0]]['link0-FirstName'] = indexed['FirstName']\n",
    "        #potential_dupes.loc[[lev0]]['link0-LastName'] = indexed['LastName']\n",
    "        \n",
    "    potential_dupes['level0-FirstName'] = fname\n",
    "    potential_dupes['level0-LastName'] = lname\n",
    "    \n",
    "    fname1 = []\n",
    "    lname1 = []\n",
    "    \n",
    "    for lev1 in potential_dupes['level_1']:\n",
    "        #potential_dupes['link1-FirstNam] = \n",
    "        indexed = df.loc[[lev1]]\n",
    "        fname1.append(indexed['FirstName'].values[0])\n",
    "        lname1.append(indexed['LastName'].values[0])\n",
    "        \n",
    "        #potential_dupes.loc[[lev0]]['link0-FirstName'] = indexed['FirstName']\n",
    "        #potential_dupes.loc[[lev0]]['link0-LastName'] = indexed['LastName']\n",
    "        \n",
    "    potential_dupes['level1-FirstName'] = fname1\n",
    "    potential_dupes['level1-LastName'] = lname1\n",
    "    \n",
    "    print(potential_dupes)\n",
    "    columnstor = [\"level_0\", \"level0-FirstName\", \"level0-LastName\", \"level_1\", \"level1-FirstName\", \"level1-LastName\", \"FirstName\", \"LastName\", \"Score\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    potential_dupes = potential_dupes.reindex(columns=columnstor)\n",
    "    \n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print(potential_dupes)\n",
    "\n",
    "\n",
    "        \n",
    "def runner2(worksheet):\n",
    "    compare_list = ['Full Name', 'Address Line1', 'Home Email']\n",
    "    thresholdVal = 0.80\n",
    "    \n",
    "    \n",
    "    df = pd.read_excel(raw_file_name, index_col=False)\n",
    "    indexer = recordlinkage.Index()\n",
    "    indexer.sortedneighbourhood(left_on='State Territory', window=3)\n",
    "    candidate_links = indexer.index(df)\n",
    "    compare_cl = recordlinkage.Compare()\n",
    "\n",
    "    #for name in compare_list:\n",
    "    #    compare_cl.string(name, name, threshold=thresholdVal, method='levenshtein', label=name)\n",
    "    \n",
    "    compare_cl.exact('Full Name', 'Full Name', label='Full Name')\n",
    "    compare_cl.exact('Address Line1', 'Address Line1', label='Address Line1')\n",
    "    compare_cl.exact('Home Email', 'Home Email', label='Home Email')\n",
    "    #compare_cl.numeric('PhoneNumber', 'PhoneNumber', method='linear', label='PhoneNumber')\n",
    "    \n",
    "\n",
    "    features = compare_cl.compute(candidate_links, df)\n",
    "    \n",
    "    #print(features.head(10))\n",
    "    #matches = features[features.sum(axis=1) > 1]\n",
    "    #print(matches)\n",
    "    #print(df)\n",
    "    \n",
    "    features.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    potential_dupes = features[features.sum(axis=1) > 0].reset_index()\n",
    "    potential_dupes['Score'] = potential_dupes.loc[:, (compare_list)].sum(axis=1)\n",
    "    #potential_dupes['Score2'] = potential_dupes.loc[:, 'FName':'LName'].sum(axis=1)\n",
    "    \n",
    "    #print(potential_dupes)\n",
    "    \n",
    "    index_list = []\n",
    "    match_list = []\n",
    "    \n",
    "    for number in range(0, len(compare_list)):\n",
    "        index_list.append([])\n",
    "        match_list.append([])\n",
    "    \n",
    "    for lev0 in potential_dupes['level_0']:\n",
    "        #potential_dupes['link1-FirstNam] = \n",
    "        indexed = df.loc[[lev0]]\n",
    "        for number in range(0, len(compare_list)):\n",
    "            index_list[number].append(indexed[compare_list[number]].values[0])\n",
    "        \n",
    "    \n",
    "    \n",
    "    for lev1 in potential_dupes['level_1']:\n",
    "        #potential_dupes['link1-FirstNam] = \n",
    "        indexed = df.loc[[lev1]]\n",
    "        for number in range(0, len(compare_list)):\n",
    "            match_list[number].append(indexed[compare_list[number]].values[0])\n",
    "    \n",
    "    columnstor = [\"Score\", \"level_0\", \"level_1\"]\n",
    "    \n",
    "    for number in range(0, len(compare_list)):\n",
    "        potential_dupes['|'] = \"\"\n",
    "        potential_dupes['Index-{}'.format(compare_list[number])] = index_list[number]\n",
    "        potential_dupes['Match-{}'.format(compare_list[number])] = match_list[number]\n",
    "        \n",
    "        columnstor.append('|')\n",
    "        columnstor.append('Index-{}'.format(compare_list[number]))\n",
    "        columnstor.append('Match-{}'.format(compare_list[number]))\n",
    "\n",
    "    \n",
    "    potential_dupes = potential_dupes.reindex(columns=columnstor)\n",
    "    potential_dupes = potential_dupes.rename({'level_0': 'Index', 'level_1': 'Match'}, axis=1)\n",
    "    \n",
    "\n",
    "    potential_dupes = potential_dupes.sort_values(by = 'Score', ascending = False)\n",
    "\n",
    "    \n",
    "    def outputfile(dfout):\n",
    "        filename = ('out_duplicates.xlsx')\n",
    "        writer = pd.ExcelWriter(filename)\n",
    "        dfout.to_excel(writer, engine='xlsxwriter', index=False, header=True)\n",
    "        writer.save()\n",
    "\n",
    "        #red_color = 'ffc7ce'\n",
    "        #red_fill = styles.PatternFill(start_color=red_color, end_color=red_color, fill_type='solid')\n",
    "        #worksheet.conditional_formatting.add('E1:B10', formatting.CellIsRule(operator='lessThan', formula=['0'], fill=red_fill))\n",
    "        \n",
    "\n",
    "    outputfile(potential_dupes)\n",
    "    display(potential_dupes)\n",
    "    #with pd.option_context('expand_frame_repr', False):\n",
    "    #    print(potential_dupes)\n",
    "        \n",
    "        \n",
    "\n",
    "#Open raw file for data access\n",
    "clean_pathlist = []\n",
    "pathlist = list((Path('./').glob('**/*.xlsx')))\n",
    "for path in pathlist:\n",
    "    if not \"duplicates\".casefold() in path.stem.casefold():\n",
    "        clean_pathlist.append(path)\n",
    "\n",
    "total = len(clean_pathlist)\n",
    "current = 1\n",
    "print(\"------------------------------------\")\n",
    "for file in clean_pathlist:\n",
    "    raw_file_name = file.resolve()\n",
    "    print(\"Total xlsx files found: {}\".format(total))\n",
    "    print(\"Starting file {}/{}: {}\".format(current, total, file))\n",
    "    workbook = openpyxl.load_workbook(raw_file_name)\n",
    "    worksheet = workbook.active\n",
    "    runner2(worksheet)\n",
    "    \n",
    "    path1 = 'C:\\\\Users\\\\Xukrao\\\\Desktop\\\\workbook1.xlsx'\n",
    "    path2 = 'C:\\\\Users\\\\Xukrao\\\\Desktop\\\\workbook2.xlsx'\n",
    "\n",
    "    wb2 = openpyxl.load_workbook('out_duplicates.xlsx')\n",
    "    ws2 = wb2.create_sheet(\"original\")\n",
    "\n",
    "    for row in worksheet:\n",
    "        for cell in row:\n",
    "            ws2[cell.coordinate].value = cell.value\n",
    "\n",
    "    wb2.save('out_duplicates.xlsx')\n",
    "    \n",
    "        \n",
    "    print(\"Matches found, check output file for information on duplicates\")\n",
    "    print(\"Done running file {}\".format(file))\n",
    "    print(\"------------------------------------\")\n",
    "        \n",
    "    #print(\"Matches found, check output file for information on duplicates\")\n",
    "    #print(\"Done running file {}\".format(file))\n",
    "    #print(\"------------------------------------\")\n",
    "    #current = current + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e0520a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1e850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install Levenshtein-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95635b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_dedupe in c:\\users\\sid\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Collecting dedupe>=2.0.0\n",
      "  Using cached dedupe-2.0.13.tar.gz (70 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: unidecode in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pandas_dedupe) (1.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pandas_dedupe) (1.3.4)\n",
      "Requirement already satisfied: BTrees>=4.1.4 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (4.9.2)\n",
      "Collecting fastcluster\n",
      "  Using cached fastcluster-1.2.4-cp39-cp39-win_amd64.whl (36 kB)\n",
      "Collecting categorical-distance>=1.9\n",
      "  Using cached categorical_distance-1.9-py3-none-any.whl (3.3 kB)\n",
      "Collecting Levenshtein-search==1.4.5\n",
      "  Using cached Levenshtein_search-1.4.5.tar.gz (7.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting haversine>=0.4.1\n",
      "  Using cached haversine-2.5.1-py2.py3-none-any.whl (6.1 kB)\n",
      "Collecting highered>=0.2.0\n",
      "  Using cached highered-0.2.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Collecting dedupe-hcluster\n",
      "  Using cached dedupe_hcluster-0.3.9-cp39-cp39-win_amd64.whl (170 kB)\n",
      "Requirement already satisfied: rlr>=2.4.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (2.4.6)\n",
      "Collecting doublemetaphone\n",
      "  Using cached DoubleMetaphone-1.1-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: simplecosine>=1.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (1.2)\n",
      "Collecting affinegap>=1.3\n",
      "  Using cached affinegap-1.12-cp39-cp39-win_amd64.whl (16 kB)\n",
      "Requirement already satisfied: zope.index in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (3.10.0.2)\n",
      "Collecting dedupe-variable-datetime\n",
      "  Using cached dedupe_variable_datetime-0.1.5-py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: numpy>=1.13 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe>=2.0.0->pandas_dedupe) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pandas->pandas_dedupe) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pandas->pandas_dedupe) (2021.3)\n",
      "Requirement already satisfied: persistent>=4.1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from BTrees>=4.1.4->dedupe>=2.0.0->pandas_dedupe) (4.7.0)\n",
      "Requirement already satisfied: zope.interface>=5.0.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from BTrees>=4.1.4->dedupe>=2.0.0->pandas_dedupe) (5.4.0)\n",
      "Requirement already satisfied: pyhacrf-datamade>=0.2.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from highered>=0.2.0->dedupe>=2.0.0->pandas_dedupe) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->pandas_dedupe) (1.16.0)\n",
      "Requirement already satisfied: pylbfgs in c:\\users\\sid\\anaconda3\\lib\\site-packages (from rlr>=2.4.3->dedupe>=2.0.0->pandas_dedupe) (0.2.0.14)\n",
      "Requirement already satisfied: datetime-distance in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe-variable-datetime->dedupe>=2.0.0->pandas_dedupe) (0.1.3)\n",
      "Requirement already satisfied: future in c:\\users\\sid\\anaconda3\\lib\\site-packages (from dedupe-variable-datetime->dedupe>=2.0.0->pandas_dedupe) (0.18.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sid\\anaconda3\\lib\\site-packages (from zope.index->dedupe>=2.0.0->pandas_dedupe) (60.9.3)\n",
      "Requirement already satisfied: cffi in c:\\users\\sid\\anaconda3\\lib\\site-packages (from persistent>=4.1.0->BTrees>=4.1.4->dedupe>=2.0.0->pandas_dedupe) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sid\\anaconda3\\lib\\site-packages (from cffi->persistent>=4.1.0->BTrees>=4.1.4->dedupe>=2.0.0->pandas_dedupe) (2.20)\n",
      "Building wheels for collected packages: dedupe, Levenshtein-search\n",
      "  Building wheel for dedupe (pyproject.toml): started\n",
      "  Building wheel for dedupe (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for Levenshtein-search (setup.py): started\n",
      "  Building wheel for Levenshtein-search (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for Levenshtein-search\n",
      "Failed to build dedupe Levenshtein-search\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for dedupe (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [46 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\api.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\backport.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\blocking.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\canonical.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\canopy_index.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\clustering.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\convenience.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\core.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\datamodel.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\index.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\labeler.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\levenshtein.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\predicates.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\sampling.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\serializer.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\tfidf.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\training.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\_init.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\_typing.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  copying dedupe\\__init__.py -> build\\lib.win-amd64-3.9\\dedupe\n",
      "  creating build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\base.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\categorical_type.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\exact.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\exists.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\interaction.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\latlong.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\price.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\set.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\string.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  copying dedupe\\variables\\__init__.py -> build\\lib.win-amd64-3.9\\dedupe\\variables\n",
      "  running build_ext\n",
      "  building 'dedupe.cpredicates' extension\n",
      "  creating build\\temp.win-amd64-3.9\n",
      "  creating build\\temp.win-amd64-3.9\\Release\n",
      "  creating build\\temp.win-amd64-3.9\\Release\\dedupe\n",
      "  \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Sid\\anaconda3\\include -IC:\\Users\\Sid\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\include\" /Tcdedupe/cpredicates.c /Fobuild\\temp.win-amd64-3.9\\Release\\dedupe/cpredicates.obj\n",
      "  cpredicates.c\n",
      "  C:\\Users\\Sid\\anaconda3\\include\\pyconfig.h(59): fatal error C1083: Cannot open include file: 'io.h': No such file or directory\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dedupe\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [11 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'Levenshtein_search' extension\n",
      "  creating build\n",
      "  creating build\\temp.win-amd64-3.9\n",
      "  creating build\\temp.win-amd64-3.9\\Release\n",
      "  \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Sid\\anaconda3\\include -IC:\\Users\\Sid\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\include\" /TcLev_search.c /Fobuild\\temp.win-amd64-3.9\\Release\\Lev_search.obj\n",
      "  Lev_search.c\n",
      "  C:\\Users\\Sid\\anaconda3\\include\\pyconfig.h(59): fatal error C1083: Cannot open include file: 'io.h': No such file or directory\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Levenshtein-search\n",
      "ERROR: Could not build wheels for dedupe, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install pandas_dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac898f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "075cc364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "162c2723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for number in range(0, 3):\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f9b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
