{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe689c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 65 rows and 10 columns to centering-river-373515.RetireeAnalyticsTest.Country\n",
      "Loaded 65 rows and 10 columns to centering-river-373515.RetireeAnalyticsTest.County\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# \"priv_key.json\"\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'priv_key.json', scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)\n",
    "\n",
    "def get_job_config(schema_in):\n",
    "    return bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        schema=schema_in,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "def dues_runner():\n",
    "    dues_paid_table_id = \"centering-river-373515.RetireeAnalyticsTest.DuesPaid\"\n",
    "    dues_job_config = get_job_config([\n",
    "        bigquery.SchemaField('id', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliatenumber', 'STRING'),\n",
    "        bigquery.SchemaField('affiliatename', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateguid', 'STRING'),\n",
    "        bigquery.SchemaField('parentaffiliatenumber', 'INTEGER'),\n",
    "        bigquery.SchemaField('parentaffiliatename', 'STRING'),\n",
    "        bigquery.SchemaField('localstateabbreviation', 'STRING'),\n",
    "        bigquery.SchemaField('paiddate', 'STRING'),\n",
    "        bigquery.SchemaField('paidyear', 'INTEGER'),\n",
    "        bigquery.SchemaField('paidmonth', 'INTEGER'),\n",
    "        bigquery.SchemaField('paidyearmonth', 'INTEGER'),\n",
    "        bigquery.SchemaField('docdate', 'STRING'),\n",
    "        bigquery.SchemaField('duesyear', 'INTEGER'),\n",
    "        bigquery.SchemaField('duesmonth', 'INTEGER'),\n",
    "        bigquery.SchemaField('duesyearmonth', 'INTEGER'),\n",
    "        bigquery.SchemaField('memberfull', 'INTEGER'),\n",
    "        bigquery.SchemaField('memberhalf', 'INTEGER'),\n",
    "        bigquery.SchemaField('memberquarter', 'INTEGER'),\n",
    "        bigquery.SchemaField('membereighth', 'INTEGER'),\n",
    "        bigquery.SchemaField('retired', 'INTEGER'),\n",
    "        bigquery.SchemaField('onleave', 'INTEGER'),\n",
    "        bigquery.SchemaField('studentmember', 'INTEGER'),\n",
    "        bigquery.SchemaField('agencyfeefull', 'INTEGER'),\n",
    "        bigquery.SchemaField('agencyfeehalf', 'INTEGER'),\n",
    "        bigquery.SchemaField('agencyfeequarter', 'INTEGER'),\n",
    "        bigquery.SchemaField('agencyfeeoneeighth', 'INTEGER'),\n",
    "        bigquery.SchemaField('ad_and_d', 'INTEGER'),\n",
    "        bigquery.SchemaField('liabilityinssurance', 'INTEGER'),\n",
    "        bigquery.SchemaField('sourcetable', 'STRING'),\n",
    "        bigquery.SchemaField('loaddate', 'STRING'),\n",
    "        bigquery.SchemaField('filename', 'STRING'),\n",
    "        bigquery.SchemaField('filedate', 'STRING'),\n",
    "    ])\n",
    "\n",
    "    with open(\"dues_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, dues_paid_table_id, job_config=dues_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(dues_paid_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), dues_paid_table_id\n",
    "        ))\n",
    "\n",
    "\n",
    "def indvaff_runner():\n",
    "    individualaff_table_id = \"centering-river-373515.RetireeAnalyticsTest.IndividualAffiliate\"\n",
    "    indvaff_job_config = get_job_config([\n",
    "        bigquery.SchemaField('individualaffiliateid', 'INTEGER'),\n",
    "        bigquery.SchemaField('individualid', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliateid', 'INTEGER'),\n",
    "        bigquery.SchemaField('unionrelationshiptypeid', 'INTEGER'),\n",
    "        bigquery.SchemaField('localduescategoryid', 'STRING'),\n",
    "        bigquery.SchemaField('hasliabilityinsurance', 'STRING'),\n",
    "        bigquery.SchemaField('hasaccidentinsurance', 'STRING'),\n",
    "        bigquery.SchemaField('iscurrent', 'INTEGER'),\n",
    "        bigquery.SchemaField('individualdeactivationreasonid', 'STRING'),\n",
    "        bigquery.SchemaField('startdate', 'STRING'),\n",
    "        bigquery.SchemaField('enddate', 'STRING'),\n",
    "        bigquery.SchemaField('paidthroughdate', 'STRING'),\n",
    "        bigquery.SchemaField('paymentmethodid', 'STRING'),\n",
    "        bigquery.SchemaField('paymentfrequencyid', 'STRING'),\n",
    "        bigquery.SchemaField('createdby', 'INTEGER'),\n",
    "        bigquery.SchemaField('createdat', 'STRING'),\n",
    "        bigquery.SchemaField('updatedby', 'INTEGER'),\n",
    "        bigquery.SchemaField('updatedat', 'STRING'),\n",
    "        bigquery.SchemaField('deletedat', 'STRING')\n",
    "    ])\n",
    "\n",
    "    with open(\"indvaff_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, individualaff_table_id, job_config=indvaff_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(individualaff_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), individualaff_table_id\n",
    "        ))\n",
    "\n",
    "def indv_runner():\n",
    "    individual_table_id = \"centering-river-373515.RetireeAnalyticsTest.Individual\"\n",
    "    indv_job_config = get_job_config([\n",
    "        bigquery.SchemaField('individualid', 'INTEGER'),\n",
    "        bigquery.SchemaField('individualguid', 'STRING'),\n",
    "        bigquery.SchemaField('firstname', 'STRING'),\n",
    "        bigquery.SchemaField('middlename', 'STRING'),\n",
    "        bigquery.SchemaField('lastname', 'STRING'),\n",
    "        bigquery.SchemaField('preferredname', 'STRING'),\n",
    "        bigquery.SchemaField('previousname', 'STRING'),\n",
    "        bigquery.SchemaField('preferredpronoun', 'STRING'),\n",
    "        bigquery.SchemaField('prefixid', 'STRING'),\n",
    "        bigquery.SchemaField('suffixid', 'STRING'),\n",
    "        bigquery.SchemaField('pictureurl', 'STRING'),\n",
    "        bigquery.SchemaField('genderid', 'STRING'),\n",
    "        bigquery.SchemaField('ethnicityid', 'STRING'),\n",
    "        bigquery.SchemaField('maritalstatusid', 'STRING'),\n",
    "        bigquery.SchemaField('dependents', 'STRING'),\n",
    "        bigquery.SchemaField('dayofbirth', 'STRING'),\n",
    "        bigquery.SchemaField('monthofbirth', 'STRING'),\n",
    "        bigquery.SchemaField('yearofbirth', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateassignedid', 'STRING'),\n",
    "        bigquery.SchemaField('billhighwayid', 'STRING'),\n",
    "        bigquery.SchemaField('ispoliticallyactive', 'INTEGER'),\n",
    "        bigquery.SchemaField('isregisteredvoter', 'INTEGER'),\n",
    "        bigquery.SchemaField('politicalpartyid', 'STRING'),\n",
    "        bigquery.SchemaField('voterprecinct', 'STRING'),\n",
    "        bigquery.SchemaField('township', 'STRING'),\n",
    "        bigquery.SchemaField('ward', 'STRING'),\n",
    "        bigquery.SchemaField('congressionaldistrict', 'STRING'),\n",
    "        bigquery.SchemaField('statesenatedistrict', 'STRING'),\n",
    "        bigquery.SchemaField('statehousedistrict', 'STRING'),\n",
    "        bigquery.SchemaField('residentialschooldistrict', 'STRING'),\n",
    "        bigquery.SchemaField('createdby', 'INTEGER'),\n",
    "        bigquery.SchemaField('createdat', 'STRING'),\n",
    "        bigquery.SchemaField('updatedby', 'INTEGER'),\n",
    "        bigquery.SchemaField('updatedat', 'STRING'),\n",
    "        bigquery.SchemaField('deletedat', 'STRING')\n",
    "    ])\n",
    "\n",
    "    with open(\"indv_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, individual_table_id, job_config=indv_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(individual_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), individual_table_id\n",
    "        ))\n",
    "\n",
    "def aff_runner():\n",
    "    aff_table_id = \"centering-river-373515.RetireeAnalyticsTest.Affiliate\"\n",
    "    aff_job_config = get_job_config([\n",
    "        bigquery.SchemaField('affiliateid', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliateguid', 'STRING'),\n",
    "        bigquery.SchemaField('affiliatename', 'STRING'),\n",
    "        bigquery.SchemaField('affiliatenumber', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateabbreviatedname', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateacronym', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateein', 'STRING'),\n",
    "        bigquery.SchemaField('affiliatepercapitapin', 'STRING'),\n",
    "        bigquery.SchemaField('billhighwaygroupid', 'STRING'),\n",
    "        bigquery.SchemaField('ischartered', 'INTEGER'),\n",
    "        bigquery.SchemaField('charterdate', 'STRING'),\n",
    "        bigquery.SchemaField('parentaffiliateid', 'STRING'),\n",
    "        bigquery.SchemaField('affiliatetypeid', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliatedesignationid', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliategeoreachid', 'INTEGER'),\n",
    "        bigquery.SchemaField('isaffiliateactive', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliateinactivereasonid', 'STRING'),\n",
    "        bigquery.SchemaField('affiliateinactivedate', 'STRING'),\n",
    "        bigquery.SchemaField('locationstateabr', 'STRING'),\n",
    "        bigquery.SchemaField('regionid', 'STRING'),\n",
    "        bigquery.SchemaField('retireeentitytypeid', 'STRING'),\n",
    "        bigquery.SchemaField('retireedestinationid', 'STRING'),\n",
    "        bigquery.SchemaField('electionmonth', 'STRING'),\n",
    "        bigquery.SchemaField('officertermstartmonth', 'STRING'),\n",
    "        bigquery.SchemaField('iselectionyearodd', 'STRING'),\n",
    "        bigquery.SchemaField('electiontermyears', 'STRING'),\n",
    "        bigquery.SchemaField('noncoaupdate', 'INTEGER'),\n",
    "        bigquery.SchemaField('nonationalupdate', 'INTEGER'),\n",
    "        bigquery.SchemaField('nostateupdate', 'INTEGER'),\n",
    "        bigquery.SchemaField('nolanwanupdate', 'INTEGER'),\n",
    "        bigquery.SchemaField('noexternalupdate', 'INTEGER'),\n",
    "        bigquery.SchemaField('affiliatewebsite', 'STRING'),\n",
    "        bigquery.SchemaField('isactionnetwork', 'STRING'),\n",
    "        bigquery.SchemaField('usesaftmemberid', 'STRING'),\n",
    "        bigquery.SchemaField('createdby', 'INTEGER'),\n",
    "        bigquery.SchemaField('createdat', 'STRING'),\n",
    "        bigquery.SchemaField('updatedby', 'INTEGER'),\n",
    "        bigquery.SchemaField('updatedat', 'STRING'),\n",
    "        bigquery.SchemaField('deletedat', 'STRING')\n",
    "    ])\n",
    "\n",
    "    with open(\"aff_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, aff_table_id, job_config=aff_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(aff_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), aff_table_id\n",
    "        ))\n",
    "\n",
    "def indvemployer_runner():\n",
    "    indvemp_table_id = \"centering-river-373515.RetireeAnalyticsTest.IndividualEmployer\"\n",
    "    indvemp_job_config = get_job_config([\n",
    "        \n",
    "        bigquery.SchemaField(\"individualemployerid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"individualid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"employerid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"employeeid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"localjobclassid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"jobtitleid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"jobdescription\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"hiredate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"startdate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"unitstartdate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"enddate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"workshift\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"retirementeffdate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"isparttime\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"istenured\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"compensationid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"payperiodtypeid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"subjectid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"worklocationid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"workstructureid\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"roomnumber\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"source\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"stopreason\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"currentlyworking\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"ispreferred\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"positionid\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"fulltimeequivalent\", \"INTEGER\"),\n",
    "        bigquery.SchemaField('createdby', 'INTEGER'),\n",
    "        bigquery.SchemaField('createdat', 'STRING'),\n",
    "        bigquery.SchemaField('updatedby', 'INTEGER'),\n",
    "        bigquery.SchemaField('updatedat', 'STRING'),\n",
    "        bigquery.SchemaField('deletedat', 'STRING')\n",
    "    ])\n",
    "\n",
    "    with open(\"indvemp_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, indvemp_table_id, job_config=indvemp_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(indvemp_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), indvemp_table_id\n",
    "        ))\n",
    "\n",
    "def ldc_runner():\n",
    "    ldc_table_id = \"centering-river-373515.RetireeAnalyticsTest.LocalDuesCategory\"\n",
    "    ldc_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"ldc_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, ldc_table_id, job_config=ldc_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(ldc_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), ldc_table_id\n",
    "        ))\n",
    "    \n",
    "def spc_runner():\n",
    "    spc_table_id = \"centering-river-373515.RetireeAnalyticsTest.StatePerCapita\"\n",
    "    spc_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"statepercap_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, spc_table_id, job_config=spc_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(spc_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), spc_table_id\n",
    "        ))\n",
    "    \n",
    "def npc_runner():\n",
    "    npc_table_id = \"centering-river-373515.RetireeAnalyticsTest.NationalPerCapita\"\n",
    "    npc_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"nationalpercap_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, npc_table_id, job_config=npc_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(npc_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), npc_table_id\n",
    "        ))\n",
    "\n",
    "def indvadd_runner():\n",
    "    indvadd_table_id = \"centering-river-373515.RetireeAnalyticsTest.IndividualAddress\"\n",
    "    indvadd_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"indvadd_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, indvadd_table_id, job_config=indvadd_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(indvadd_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), indvadd_table_id\n",
    "        ))\n",
    "    \n",
    "def indvemail_runner():\n",
    "    indvemail_table_id = \"centering-river-373515.RetireeAnalyticsTest.IndividualEmail\"\n",
    "    indvemail_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"indvemail_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, indvemail_table_id, job_config=indvemail_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(indvemail_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), indvemail_table_id\n",
    "        ))\n",
    "    \n",
    "def indvphone_runner():\n",
    "    indvphone_table_id = \"centering-river-373515.RetireeAnalyticsTest.IndividualPhone\"\n",
    "    indvphone_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        schema=[bigquery.SchemaField('extension', 'STRING')],\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"indvph_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, indvphone_table_id, job_config=indvphone_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(indvphone_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), indvphone_table_id\n",
    "        ))\n",
    "\n",
    "def state_runner():\n",
    "    state_table_id = \"centering-river-373515.RetireeAnalyticsTest.StateTerritory\"\n",
    "    state_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"state_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, state_table_id, job_config=state_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(state_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), state_table_id\n",
    "        ))\n",
    "    \n",
    "def country_runner():\n",
    "    country_table_id = \"centering-river-373515.RetireeAnalyticsTest.Country\"\n",
    "    country_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"country_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, country_table_id, job_config=country_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(country_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), country_table_id\n",
    "        ))\n",
    "    \n",
    "def county_runner():\n",
    "    county_table_id = \"centering-river-373515.RetireeAnalyticsTest.County\"\n",
    "    county_job_config = bigquery.LoadJobConfig(\n",
    "        allow_quoted_newlines=True,\n",
    "        allow_jagged_rows=True,\n",
    "        source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1, autodetect=True, write_disposition = 'WRITE_TRUNCATE'\n",
    "    )\n",
    "\n",
    "    with open(\"county_upload.csv\", \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, county_table_id, job_config=county_job_config)\n",
    "    job.result()  # Waits for the job to complete.\n",
    "\n",
    "    table = client.get_table(county_table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), county_table_id\n",
    "        ))\n",
    "    \n",
    "\n",
    "# indv_runner()\n",
    "# indvaff_runner()\n",
    "# aff_runner()\n",
    "# dues_runner()\n",
    "\n",
    "#indvemployer_runner()\n",
    "#ldc_runner()\n",
    "#spc_runner()\n",
    "#npc_runner()\n",
    "# indvadd_runner()\n",
    "# indvemail_runner()\n",
    "#indvphone_runner()\n",
    "country_runner()\n",
    "county_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568412e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\sid\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (4.21.12)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.26.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (1.51.1)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (21.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (2.16.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.51.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from packaging>=20.0.0->google-cloud-bigquery) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (5.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sid\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7586145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
